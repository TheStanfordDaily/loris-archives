{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (80, 80)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the whole point of this thing is to open up corners of the collection that were otherwise inacessible because of the bad algorithm. But how do we know that we've done that? We can much around with the demo but it's not really telling us how much of the collection we can _actually_ access through the mapping of one manifold to another.\n",
    "\n",
    "I want to float through all of sentence space and see how many of the works i can touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = np.load('../data/image_ids.npy')\n",
    "embeddings = np.load('../data/embeddings.npy').reshape(-1, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000\n",
    "sample_indicies = np.random.choice(len(embeddings), \n",
    "                                   size=n_samples, \n",
    "                                   replace=False)\n",
    "\n",
    "image_id_sample = image_ids[sample_indicies]\n",
    "embeddings_sample = embeddings[sample_indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality reduction\n",
    "### 2D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = UMAP(n_neighbors=10, \n",
    "              n_components=2,\n",
    "              metric='cosine')\n",
    "\n",
    "embeddings_2d = fitter.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2d = (AgglomerativeClustering(n_clusters=20)\n",
    "             .fit_predict(embeddings_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(embeddings_2d[:, 0], \n",
    "           embeddings_2d[:, 1],\n",
    "           s=4,  alpha=0.2,\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = UMAP(n_neighbors=10, \n",
    "              n_components=3,\n",
    "              metric='cosine')\n",
    "\n",
    "embeddings_3d = fitter.fit_transform(embeddings_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_3d = (AgglomerativeClustering(n_clusters=20)\n",
    "             .fit_predict(embeddings_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(embeddings_3d[:, 0], \n",
    "           embeddings_3d[:, 1],\n",
    "           embeddings_3d[:, 2],\n",
    "           s=1, c=labels_3d, alpha=0.2,\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting with datashader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from bokeh.models import BoxZoomTool\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "import datashader as ds\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "from functools import partial\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings_2d)\n",
    "df.columns = ['x', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = ds.Canvas(plot_width=400, plot_height=400)\n",
    "agg = cvs.points(df, 'x', 'y')\n",
    "img = tf.shade(agg, how='eq_hist')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_plot(tools='pan, wheel_zoom, reset',\n",
    "              plot_width=plot_width, \n",
    "              plot_height=plot_height, \n",
    "              **plot_args):\n",
    "    p = figure(tools=tools, \n",
    "               plot_width=plot_width, \n",
    "               plot_height=plot_height,\n",
    "               x_range=x_range, \n",
    "               y_range=y_range, \n",
    "               outline_line_color='grey',\n",
    "               min_border=0, \n",
    "               min_border_left=0, \n",
    "               min_border_right=0,\n",
    "               min_border_top=0, \n",
    "               min_border_bottom=0, \n",
    "               **plot_args)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.add_tools(BoxZoomTool(match_aspect=True))\n",
    "    return p\n",
    "\n",
    "\n",
    "def create_image(x_range, y_range, width=950, height=950):\n",
    "    cvs = ds.Canvas(plot_width=width, plot_height=height, \n",
    "                    x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.points(df, 'x', 'y')\n",
    "    img = tf.shade(agg, how='eq_hist')\n",
    "    return tf.dynspread(img, max_px=5, shape='circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = df['x'].min(), df['x'].max()\n",
    "y_range = df['y'].min(), df['y'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = base_plot(background_fill_color='white')\n",
    "InteractiveImage(p, create_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datashader doesn't allow you to add annotations to points... very annoying. Back to static plots then...\n",
    "# Grabbing little clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = UMAP(n_neighbors=10, \n",
    "              n_components=2,\n",
    "              metric='cosine')\n",
    "\n",
    "embeddings_2d = fitter.fit_transform(embeddings_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "somewhere around 50 points per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = int(n_samples / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_2d = (AgglomerativeClustering(n_clusters=n_clusters)\n",
    "             .fit_predict(embeddings_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(embeddings_2d[:, 0], \n",
    "           embeddings_2d[:, 1],\n",
    "           s=4, alpha=0.8, c=labels_2d\n",
    "          );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=image_id_sample,\n",
    "                  data=np.hstack([embeddings_2d, \n",
    "                                  labels_2d.reshape(-1,1)]))\n",
    "\n",
    "df.columns = ['x', 'y', 'cluster']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cluster = np.random.choice(df['cluster'].unique())\n",
    "cluster_df = df[df['cluster'] == chosen_cluster]\n",
    "print(len(cluster_df))\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_length = int(np.floor(np.sqrt(len(cluster_df))))\n",
    "n_images = int(side_length ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_image_ids = np.random.choice(cluster_df.index.values, \n",
    "                                     size=n_images, \n",
    "                                     replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://iiif.wellcomecollection.org/image/{}.jpg/full/760,/0/default.jpg'\n",
    "urls = [base_url.format(image_id) for image_id in cluster_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_url(url, image_size=200):\n",
    "    raw_image = Image.open(BytesIO(requests.get(url).content))\n",
    "    resized_image = raw_image.resize((image_size, image_size), \n",
    "                                     resample=Image.BILINEAR)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (np.array([np.array(image_from_url(url)) for url in urls])\n",
    "          .reshape(side_length, side_length, 200, 200, 3)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(side_length*200, side_length*200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/pimh/datasets/wikitext-103/wiki.train.tokens') as f:\n",
    "    articles = f.read().split('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for article in tqdm(articles[:10000]):\n",
    "    for sentence in nlp(article).sents:\n",
    "        if len(sentence) > 1:\n",
    "            sentences.append(str(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentenceEncoder, self).__init__()\n",
    "        self.enc_lstm = nn.LSTM(\n",
    "            input_size=300, hidden_size=2048, num_layers=1, bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self, wv_batch):\n",
    "        embedded, _ = self.enc_lstm(wv_batch)\n",
    "        max_pooled = torch.max(embedded, 1)[0] \n",
    "        return max_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceEncoder()\n",
    "model.load_state_dict(\n",
    "    torch.load('../../../apps/devise/data/sentence-encoder-2018-10-16.pt', \n",
    "               map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "word_to_index = pickle.load(open('../../../apps/devise/data/word_to_index.pkl', 'rb'))\n",
    "index_to_wordvec = np.load('../../../apps/devise/data/index_to_wordvec.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def sentence_to_indexes(sentence, word_to_index):\n",
    "    sentence = ''.join([c if c.isalpha() else ' ' \n",
    "                        for c in sentence.lower()])\n",
    "    tokenised = word_tokenize(sentence)\n",
    "    indexes = [word_to_index[word] for word in tokenised if word in word_to_index]\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def embed(sentence, model, word_to_index, index_to_wordvec):\n",
    "    indexes = (\n",
    "        [word_to_index[\"<s>\"]]\n",
    "        + sentence_to_indexes(sentence, word_to_index)\n",
    "        + [word_to_index[\"</s>\"]]\n",
    "    )\n",
    "    wvs = np.stack([index_to_wordvec[i] for i in indexes])\n",
    "    embedding = model(torch.Tensor([wvs])).detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "\n",
    "def search(\n",
    "    query_string, search_index, model, image_ids, word_to_index, index_to_wordvec, k=10\n",
    "):\n",
    "    query_embedding = embed(query_string, model, word_to_index, index_to_wordvec)\n",
    "    neighbour_indexes, _ = search_index.knnQuery(query_embedding, k)\n",
    "    return image_ids[neighbour_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = np.array([embed(sentence=sentence,\n",
    "                                      model=model,\n",
    "                                      word_to_index=word_to_index,\n",
    "                                      index_to_wordvec=index_to_wordvec)\n",
    "                                for sentence in tqdm(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = UMAP(n_neighbors=10, \n",
    "              n_components=2,\n",
    "              metric='cosine')\n",
    "\n",
    "sentence_embeddings_2d = fitter.fit_transform(sentence_embeddings)\n",
    "\n",
    "n_clusters = int(n_samples / 50)\n",
    "\n",
    "labels_2d = (AgglomerativeClustering(n_clusters=n_clusters)\n",
    "             .fit_predict(sentence_embeddings))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(sentence_embeddings_2d[:, 0], \n",
    "           sentence_embeddings_2d[:, 1],\n",
    "           s=40, alpha=0.8, c=labels_2d\n",
    "          );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cluster = np.random.choice(np.unique(labels_2d))\n",
    "print(np.array(sentences)[np.where(labels_2d == chosen_cluster)])\n",
    "\n",
    "colours = np.full(len(sentences), fill_value='#606060')\n",
    "for index in np.where(labels_2d == chosen_cluster): \n",
    "    colours[index] = '#f44242'\n",
    "\n",
    "sizes = np.full(len(sentences), fill_value=40)\n",
    "for index in np.where(labels_2d == chosen_cluster): \n",
    "    sizes[index] = 150\n",
    "\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(sentence_embeddings_2d[:, 0], \n",
    "           sentence_embeddings_2d[:, 1],\n",
    "           s=sizes, alpha=0.8, c=colours\n",
    "          );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
